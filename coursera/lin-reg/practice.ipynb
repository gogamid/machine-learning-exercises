{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression with One Variable \n",
    "So far in this course, you have developed a linear model that predicts $f_{w,b}(x^{(i)})$:\n",
    "$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$\n",
    "In linear regression, you utilize input training data to fit the parameters $w$,$b$ by minimizing a measure of the error between our predictions $f_{w,b}(x^{(i)})$ and the actual data $y^{(i)}$. The measure is called the $cost$, $J(w,b)$. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a633e09ab2e35897"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T12:01:31.985413Z",
     "start_time": "2023-11-30T12:01:31.954997Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "x_train = np.array([1.0, 2.0])  #features\n",
    "y_train = np.array([300.0, 500.0])  #target value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T12:01:31.985984Z",
     "start_time": "2023-11-30T12:01:31.958822Z"
    }
   },
   "id": "1ae5c601a13e22fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\\tag{2}$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e64f3386d41797a"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_cost(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    total_cost = 0\n",
    "    for i in range(m):\n",
    "        f_wb_i = w * x[i] + b\n",
    "        cost_i = (f_wb_i - y[i]) ** 2\n",
    "        total_cost += cost_i\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "print(compute_cost(x_train, y_train, 200, 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T12:01:31.986082Z",
     "start_time": "2023-11-30T12:01:31.962452Z"
    }
   },
   "id": "943bb9af734ea4b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "545f18ba3f18cb4f"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    for i in range(m):\n",
    "        f_wb_i = w * x[i] + b\n",
    "        dj_dw_i = (f_wb_i - y[i]) * x[i]\n",
    "        dj_db_i = (f_wb_i - y[i])\n",
    "        dj_dw += dj_dw_i\n",
    "        dj_db += dj_db_i\n",
    "    return dj_dw / m, dj_db / m\n",
    "\n",
    "\n",
    "print(compute_gradient(x_train, y_train, 200, 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T12:01:32.010072Z",
     "start_time": "2023-11-30T12:01:31.970627Z"
    }
   },
   "id": "c5b7dd4b0c71cc2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline\n",
    "b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76130ac789b15eea"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function):\n",
    "    Js = []\n",
    "    ps = []\n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = gradient_function(x, y, w, b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        if i % 1000 == 0:\n",
    "            J_i = cost_function(x, y, w, b)\n",
    "            Js.append(J_i)\n",
    "            ps.append((w, b))\n",
    "            print(f\"Iteration {i}: cost: {J_i:.4f}, w: {w:.4f} b: {b:.4f}\")\n",
    "    return w, b, Js, ps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T12:01:32.010202Z",
     "start_time": "2023-11-30T12:01:31.974934Z"
    }
   },
   "id": "30319107735e335a"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: cost: 317099.2500, w: 6.5000 b: 4.0000\n",
      "Iteration 1000: cost: 13.6500, w: 194.9148 b: 108.2280\n",
      "Iteration 2000: cost: 3.1716, w: 197.5488 b: 103.9661\n",
      "Iteration 3000: cost: 0.7369, w: 198.8185 b: 101.9118\n",
      "Iteration 4000: cost: 0.1712, w: 199.4305 b: 100.9215\n",
      "Iteration 5000: cost: 0.0398, w: 199.7255 b: 100.4442\n",
      "Iteration 6000: cost: 0.0092, w: 199.8677 b: 100.2141\n",
      "Iteration 7000: cost: 0.0021, w: 199.9362 b: 100.1032\n",
      "Iteration 8000: cost: 0.0005, w: 199.9693 b: 100.0497\n",
      "Iteration 9000: cost: 0.0001, w: 199.9852 b: 100.0240\n",
      "Iteration 10000: cost: 0.0000, w: 199.9929 b: 100.0116\n",
      "Iteration 11000: cost: 0.0000, w: 199.9966 b: 100.0056\n",
      "Iteration 12000: cost: 0.0000, w: 199.9983 b: 100.0027\n",
      "Iteration 13000: cost: 0.0000, w: 199.9992 b: 100.0013\n",
      "Iteration 14000: cost: 0.0000, w: 199.9996 b: 100.0006\n",
      "Iteration 15000: cost: 0.0000, w: 199.9998 b: 100.0003\n",
      "Iteration 16000: cost: 0.0000, w: 199.9999 b: 100.0001\n",
      "Iteration 17000: cost: 0.0000, w: 200.0000 b: 100.0001\n",
      "Iteration 18000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 19000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 20000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 21000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 22000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 23000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 24000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 25000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 26000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 27000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 28000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 29000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 30000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 31000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 32000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 33000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 34000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 35000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 36000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 37000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 38000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 39000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 40000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 41000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 42000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 43000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 44000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 45000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 46000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 47000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 48000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 49000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 50000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 51000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 52000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 53000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 54000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 55000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 56000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 57000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 58000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 59000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 60000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 61000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 62000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 63000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 64000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 65000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 66000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 67000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 68000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 69000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 70000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 71000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 72000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 73000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 74000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 75000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 76000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 77000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 78000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 79000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 80000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 81000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 82000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 83000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 84000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 85000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 86000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 87000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 88000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 89000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 90000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 91000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 92000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 93000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 94000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 95000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 96000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 97000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 98000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "Iteration 99000: cost: 0.0000, w: 200.0000 b: 100.0000\n",
      "(w,b) found by gradient descent: (200.0000,100.0000)\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "# some gradient descent settings\n",
    "iterations = 100000\n",
    "tmp_alpha = 1.0e-2\n",
    "# run gradient descent\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(x_train, y_train, w_init, b_init, tmp_alpha,\n",
    "                                                    iterations, compute_cost, compute_gradient)\n",
    "print(f\"(w,b) found by gradient descent: ({w_final:8.4f},{b_final:8.4f})\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T12:01:32.110840Z",
     "start_time": "2023-11-30T12:01:31.991169Z"
    }
   },
   "id": "34834a91de38075c"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 sqft house prediction 300.0 Thousand dollars\n",
      "1200 sqft house prediction 340.0 Thousand dollars\n",
      "2000 sqft house prediction 500.0 Thousand dollars\n"
     ]
    }
   ],
   "source": [
    "print(f\"1000 sqft house prediction {w_final * 1.0 + b_final:0.1f} Thousand dollars\")\n",
    "print(f\"1200 sqft house prediction {w_final * 1.2 + b_final:0.1f} Thousand dollars\")\n",
    "print(f\"2000 sqft house prediction {w_final * 2.0 + b_final:0.1f} Thousand dollars\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T12:01:32.115367Z",
     "start_time": "2023-11-30T12:01:32.111042Z"
    }
   },
   "id": "24ae03cb5f8adb77"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T12:01:32.115484Z",
     "start_time": "2023-11-30T12:01:32.113152Z"
    }
   },
   "id": "d9d6dbd554e42bd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
